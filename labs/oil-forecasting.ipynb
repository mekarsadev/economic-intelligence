{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ee6608-0460-499a-b289-69aa6fdf89df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "021db3a7-14b9-4662-a2ea-e4f443557f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 8.],\n",
      "        [3., 6.]]) tensor([[12.],\n",
      "        [ 9.]])\n",
      "+-----------------------------------+\n",
      "tensor([[1., 2.],\n",
      "        [2., 4.]]) tensor([[3.],\n",
      "        [6.]])\n",
      "+-----------------------------------+\n",
      "Epoch 1, Loss: 2.411588430404663\n",
      "tensor([[1., 2.],\n",
      "        [4., 8.]]) tensor([[ 3.],\n",
      "        [12.]])\n",
      "+-----------------------------------+\n",
      "tensor([[3., 6.],\n",
      "        [2., 4.]]) tensor([[9.],\n",
      "        [6.]])\n",
      "+-----------------------------------+\n",
      "Epoch 2, Loss: 0.06810042262077332\n",
      "tensor([[3., 6.],\n",
      "        [1., 2.]]) tensor([[9.],\n",
      "        [3.]])\n",
      "+-----------------------------------+\n",
      "tensor([[4., 8.],\n",
      "        [2., 4.]]) tensor([[12.],\n",
      "        [ 6.]])\n",
      "+-----------------------------------+\n",
      "Epoch 3, Loss: 0.0017325824592262506\n",
      "tensor([[4., 8.],\n",
      "        [1., 2.]]) tensor([[12.],\n",
      "        [ 3.]])\n",
      "+-----------------------------------+\n",
      "tensor([[3., 6.],\n",
      "        [2., 4.]]) tensor([[9.],\n",
      "        [6.]])\n",
      "+-----------------------------------+\n",
      "Epoch 4, Loss: 0.0013137826463207603\n",
      "tensor([[1., 2.],\n",
      "        [2., 4.]]) tensor([[3.],\n",
      "        [6.]])\n",
      "+-----------------------------------+\n",
      "tensor([[4., 8.],\n",
      "        [3., 6.]]) tensor([[12.],\n",
      "        [ 9.]])\n",
      "+-----------------------------------+\n",
      "Epoch 5, Loss: 0.0038445168174803257\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Dummy data\n",
    "data = torch.tensor([[1.0, 2.0], [2.0, 4.0], [3.0, 6.0], [4.0, 8.0]])\n",
    "targets = torch.tensor([[3.0], [6.0], [9.0], [12.0]])\n",
    "\n",
    "# Buat DataLoader\n",
    "dataset = torch.utils.data.TensorDataset(data, targets)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# Definisikan model Anda dan optimizer (contoh sederhana)\n",
    "model = torch.nn.Linear(2, 1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Definisikan Mean Squared Error (MSE) loss\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(5):\n",
    "    for batch_data, batch_targets in dataloader:\n",
    "        print(batch_data, batch_targets)\n",
    "        print(\"+-----------------------------------+\")\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        predictions = model(batch_data)\n",
    "\n",
    "        # Hitung loss\n",
    "        loss = loss_fn(predictions, batch_targets)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7362c87c-999d-4b4e-9ca0-c547f103ac1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6., 7., 8.],\n",
      "        [2., 3., 4.]]) tensor([18., 10.])\n",
      "+------------------------------+\n",
      "tensor([[4., 5., 6.],\n",
      "        [1., 2., 3.]]) tensor([14.,  8.])\n",
      "+------------------------------+\n",
      "tensor([[7., 8., 9.],\n",
      "        [3., 4., 5.]]) tensor([20., 12.])\n",
      "+------------------------------+\n",
      "tensor([[5., 6., 7.]]) tensor([16.])\n",
      "+------------------------------+\n",
      "Epoch 1, Loss: 23.2703914642334\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]]) tensor([ 8., 14.])\n",
      "+------------------------------+\n",
      "tensor([[7., 8., 9.],\n",
      "        [5., 6., 7.]]) tensor([20., 16.])\n",
      "+------------------------------+\n",
      "tensor([[6., 7., 8.],\n",
      "        [3., 4., 5.]]) tensor([18., 12.])\n",
      "+------------------------------+\n",
      "tensor([[2., 3., 4.]]) tensor([10.])\n",
      "+------------------------------+\n",
      "Epoch 2, Loss: 2.0164029598236084\n",
      "tensor([[5., 6., 7.],\n",
      "        [2., 3., 4.]]) tensor([16., 10.])\n",
      "+------------------------------+\n",
      "tensor([[6., 7., 8.],\n",
      "        [7., 8., 9.]]) tensor([18., 20.])\n",
      "+------------------------------+\n",
      "tensor([[4., 5., 6.],\n",
      "        [1., 2., 3.]]) tensor([14.,  8.])\n",
      "+------------------------------+\n",
      "tensor([[3., 4., 5.]]) tensor([12.])\n",
      "+------------------------------+\n",
      "Epoch 3, Loss: 0.05544603615999222\n",
      "tensor([[2., 3., 4.],\n",
      "        [1., 2., 3.]]) tensor([10.,  8.])\n",
      "+------------------------------+\n",
      "tensor([[5., 6., 7.],\n",
      "        [4., 5., 6.]]) tensor([16., 14.])\n",
      "+------------------------------+\n",
      "tensor([[6., 7., 8.],\n",
      "        [7., 8., 9.]]) tensor([18., 20.])\n",
      "+------------------------------+\n",
      "tensor([[3., 4., 5.]]) tensor([12.])\n",
      "+------------------------------+\n",
      "Epoch 4, Loss: 0.4103209674358368\n",
      "tensor([[5., 6., 7.],\n",
      "        [1., 2., 3.]]) tensor([16.,  8.])\n",
      "+------------------------------+\n",
      "tensor([[2., 3., 4.],\n",
      "        [4., 5., 6.]]) tensor([10., 14.])\n",
      "+------------------------------+\n",
      "tensor([[6., 7., 8.],\n",
      "        [7., 8., 9.]]) tensor([18., 20.])\n",
      "+------------------------------+\n",
      "tensor([[3., 4., 5.]]) tensor([12.])\n",
      "+------------------------------+\n",
      "Epoch 5, Loss: 36.00453186035156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pabrik/working/mekarsa/products/economics/analyzer/venv/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Dummy data\n",
    "data = torch.tensor([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0])\n",
    "targets = torch.tensor([2.0, 4.0, 6.0, 8.0, 10.0, 12.0, 14.0, 16.0, 18.0, 20.0])\n",
    "\n",
    "# Split data into sequences\n",
    "sequence_length = 3\n",
    "sequences = []\n",
    "next_targets = []\n",
    "for i in range(len(data) - sequence_length):\n",
    "    sequences.append(data[i:i+sequence_length])\n",
    "    next_targets.append(targets[i+sequence_length])\n",
    "\n",
    "# Convert to tensors\n",
    "sequences = torch.stack(sequences)\n",
    "next_targets = torch.stack(next_targets)\n",
    "\n",
    "# Create Dataset and DataLoader\n",
    "dataset = torch.utils.data.TensorDataset(sequences, next_targets)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# Define your model and optimizer (example simple model)\n",
    "model = torch.nn.Linear(sequence_length, 1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Define Mean Squared Error (MSE) loss\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(5):\n",
    "    for batch_sequences, batch_next_targets in dataloader:\n",
    "        print(batch_sequences, batch_next_targets)\n",
    "        print(\"+------------------------------+\")\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        predictions = model(batch_sequences)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = loss_fn(predictions.squeeze(), batch_next_targets)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea5d86c0-d9af-4d69-a21a-a1912d214806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10]), torch.Size([10]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c115454e-0691-4873-8a4d-b4d7a7e08793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Loss:  0.9044798016548157\n",
      "MSE Loss:  1.6105905771255493\n",
      "MSE Loss:  1.1529138088226318\n",
      "MSE Loss:  1.3033933639526367\n",
      "MSE Loss:  0.749358057975769\n",
      "MSE Loss:  2.405273199081421\n",
      "MSE Loss:  3.8140811920166016\n",
      "MSE Loss:  0.8594918251037598\n",
      "MSE Loss:  2.856786012649536\n",
      "MSE Loss:  0.8489143252372742\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Definisikan dataset Anda\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "# Contoh data (dapat diganti dengan data Anda sendiri)\n",
    "data = torch.randn(100, 1)\n",
    "targets = torch.randn(100, 1)\n",
    "\n",
    "# Inisialisasi DataLoader\n",
    "dataset = CustomDataset(list(zip(data, targets)))\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "# Inisialisasi model dan loss function\n",
    "model = nn.Linear(1, 1)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Loop melalui setiap batch dalam DataLoader\n",
    "for batch in dataloader:\n",
    "    inputs, targets = batch\n",
    "    \n",
    "    # Reset gradien\n",
    "    model.zero_grad()\n",
    "    \n",
    "    # Hitung output model\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # Hitung loss\n",
    "    loss = criterion(outputs, targets)\n",
    "    \n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update parameter model\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Tampilkan loss\n",
    "    print(\"MSE Loss: \", loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8d3f507-e58a-43e5-80b9-d9deee57f3f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([-1.4207]), tensor([-0.5652])),\n",
       " (tensor([-0.9099]), tensor([0.1320])),\n",
       " (tensor([1.3217]), tensor([-0.0725])),\n",
       " (tensor([-1.1514]), tensor([-0.2268])),\n",
       " (tensor([-0.1645]), tensor([1.2981])),\n",
       " (tensor([-0.7324]), tensor([-0.6122])),\n",
       " (tensor([0.9532]), tensor([0.0832])),\n",
       " (tensor([0.0025]), tensor([-1.1895])),\n",
       " (tensor([-0.0892]), tensor([1.0167])),\n",
       " (tensor([0.2030]), tensor([0.5355])),\n",
       " (tensor([-0.7983]), tensor([-0.3132])),\n",
       " (tensor([-0.8797]), tensor([-0.2771])),\n",
       " (tensor([-0.7805]), tensor([-0.4865])),\n",
       " (tensor([-1.7532]), tensor([1.5360])),\n",
       " (tensor([0.6920]), tensor([-0.4155])),\n",
       " (tensor([-1.0876]), tensor([-1.0180])),\n",
       " (tensor([-0.6236]), tensor([-0.7386])),\n",
       " (tensor([-0.9927]), tensor([-0.1602])),\n",
       " (tensor([-0.4787]), tensor([0.1146])),\n",
       " (tensor([1.1122]), tensor([-2.1933])),\n",
       " (tensor([1.2549]), tensor([1.3161])),\n",
       " (tensor([-0.9870]), tensor([-1.8248])),\n",
       " (tensor([0.5345]), tensor([1.6953])),\n",
       " (tensor([-0.5064]), tensor([-0.5439])),\n",
       " (tensor([-0.0323]), tensor([0.4576])),\n",
       " (tensor([-0.3563]), tensor([-0.1924])),\n",
       " (tensor([-0.2015]), tensor([-0.7601])),\n",
       " (tensor([-1.4014]), tensor([-1.8062])),\n",
       " (tensor([-2.6316]), tensor([-0.5543])),\n",
       " (tensor([-1.2841]), tensor([-0.2342])),\n",
       " (tensor([0.8514]), tensor([0.2584])),\n",
       " (tensor([0.8101]), tensor([-0.0416])),\n",
       " (tensor([1.9948]), tensor([-0.6700])),\n",
       " (tensor([-0.9111]), tensor([0.3174])),\n",
       " (tensor([-0.1119]), tensor([0.0893])),\n",
       " (tensor([0.5193]), tensor([0.4787])),\n",
       " (tensor([0.6680]), tensor([0.2074])),\n",
       " (tensor([1.9635]), tensor([-0.2220])),\n",
       " (tensor([-0.0894]), tensor([0.9005])),\n",
       " (tensor([-0.9613]), tensor([0.9285])),\n",
       " (tensor([2.2074]), tensor([-0.0550])),\n",
       " (tensor([-1.7219]), tensor([-1.0982])),\n",
       " (tensor([-0.1709]), tensor([0.7241])),\n",
       " (tensor([-0.3196]), tensor([0.5543])),\n",
       " (tensor([-0.3035]), tensor([2.7834])),\n",
       " (tensor([-0.4795]), tensor([0.3753])),\n",
       " (tensor([1.1264]), tensor([-0.1895])),\n",
       " (tensor([-0.5807]), tensor([1.3182])),\n",
       " (tensor([0.0770]), tensor([1.4381])),\n",
       " (tensor([-0.6557]), tensor([-0.4056])),\n",
       " (tensor([2.5327]), tensor([0.4322])),\n",
       " (tensor([-0.7456]), tensor([-1.1254])),\n",
       " (tensor([0.4977]), tensor([0.1651])),\n",
       " (tensor([-0.2245]), tensor([1.1692])),\n",
       " (tensor([0.4480]), tensor([1.2763])),\n",
       " (tensor([0.4037]), tensor([-1.1222])),\n",
       " (tensor([0.6818]), tensor([-2.7003])),\n",
       " (tensor([-1.7245]), tensor([-0.0128])),\n",
       " (tensor([0.8310]), tensor([0.6154])),\n",
       " (tensor([-0.6573]), tensor([-1.7713])),\n",
       " (tensor([-0.4305]), tensor([-0.2643])),\n",
       " (tensor([-1.2323]), tensor([-0.3519])),\n",
       " (tensor([-1.3816]), tensor([-0.1315])),\n",
       " (tensor([0.3359]), tensor([0.0332])),\n",
       " (tensor([-0.9081]), tensor([0.0392])),\n",
       " (tensor([0.5957]), tensor([-0.9749])),\n",
       " (tensor([0.5034]), tensor([-0.8422])),\n",
       " (tensor([0.6767]), tensor([0.8402])),\n",
       " (tensor([-0.3601]), tensor([-0.2240])),\n",
       " (tensor([0.0382]), tensor([-0.7227])),\n",
       " (tensor([0.8786]), tensor([0.5494])),\n",
       " (tensor([-0.8350]), tensor([-0.8052])),\n",
       " (tensor([0.2064]), tensor([0.5452])),\n",
       " (tensor([-0.4983]), tensor([-0.5989])),\n",
       " (tensor([-1.2288]), tensor([-0.2754])),\n",
       " (tensor([-0.0558]), tensor([1.8591])),\n",
       " (tensor([-0.7184]), tensor([0.0446])),\n",
       " (tensor([0.8734]), tensor([0.5593])),\n",
       " (tensor([0.3010]), tensor([-0.7320])),\n",
       " (tensor([0.0375]), tensor([-0.7559])),\n",
       " (tensor([0.0589]), tensor([0.3241])),\n",
       " (tensor([-0.4286]), tensor([-1.0583])),\n",
       " (tensor([0.8451]), tensor([0.1879])),\n",
       " (tensor([0.4059]), tensor([1.3071])),\n",
       " (tensor([0.7850]), tensor([1.1923])),\n",
       " (tensor([-3.1150]), tensor([-1.1733])),\n",
       " (tensor([-0.4529]), tensor([-1.0280])),\n",
       " (tensor([0.4848]), tensor([0.8605])),\n",
       " (tensor([0.4855]), tensor([0.8984])),\n",
       " (tensor([1.1985]), tensor([-1.0032])),\n",
       " (tensor([-0.8338]), tensor([-1.0480])),\n",
       " (tensor([2.0767]), tensor([1.0514])),\n",
       " (tensor([1.2204]), tensor([-0.3972])),\n",
       " (tensor([0.0789]), tensor([-0.6898])),\n",
       " (tensor([0.3708]), tensor([1.7915])),\n",
       " (tensor([1.0395]), tensor([-0.5302])),\n",
       " (tensor([1.0834]), tensor([0.3816])),\n",
       " (tensor([0.2677]), tensor([-0.8740])),\n",
       " (tensor([1.5448]), tensor([-0.1091])),\n",
       " (tensor([1.7216]), tensor([-1.6098]))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5bb3154-2597-4988-bdb1-33665b59fe97",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m inputs \u001b[38;5;241m=\u001b[39m windows\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28mlen\u001b[39m(windows), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Hitung output model\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Hitung loss\u001b[39;00m\n\u001b[1;32m     40\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n",
      "File \u001b[0;32m~/working/mekarsa/products/economics/analyzer/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/working/mekarsa/products/economics/analyzer/venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Definisikan dataset Anda\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, window_size):\n",
    "        self.data = data\n",
    "        self.window_size = window_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        window = self.data[index:index+self.window_size]\n",
    "        target = self.data[index+self.window_size]\n",
    "        return window, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.window_size\n",
    "\n",
    "# Contoh data (dapat diganti dengan data Anda sendiri)\n",
    "data = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "\n",
    "# Inisialisasi DataLoader dengan window_size = 3\n",
    "dataset = CustomDataset(data, window_size=3)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# Loop melalui setiap batch dalam DataLoader\n",
    "for batch in dataloader:\n",
    "    windows, targets = batch\n",
    "    \n",
    "    # Reset gradien\n",
    "    model.zero_grad()\n",
    "    \n",
    "    # Flatten windows menjadi batched input\n",
    "    inputs = windows.view(len(windows), -1)\n",
    "    \n",
    "    # Hitung output model\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # Hitung loss\n",
    "    loss = criterion(outputs, targets)\n",
    "    \n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update parameter model\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Tampilkan loss\n",
    "    print(\"MSE Loss: \", loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fba23794-7ffb-4230-9bec-d9ba3b45e8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4, 5, 6],\n",
       "         [5, 6, 7]]),\n",
       " tensor([7, 8]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs, targets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
